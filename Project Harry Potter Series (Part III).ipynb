{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Welcome to Part III! In Part II, you generated text-related metrics and visualized them with barplots. \n",
    "\n",
    "In this Part, you will perform sentiment analysis on the text. More specifically, you will chart how the sentiments move over parts of the texts. \n",
    "\n",
    "You execute this by:\n",
    "- splitting a text into sentences\n",
    "- measuring the sentiment in each sentence\n",
    "- plotting the sentiments in each sentence\n",
    "- splitting the text by chapters\n",
    "- measure aggregate sentiment by chapters\n",
    "- normalizing the length of the chapters for cross-text comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "First up, let's get our libraries.\n",
    "- pandas as pd\n",
    "- matplotlib.pyplot as plt\n",
    "- SentimentIntensityAnalyzer from vaderSentiment.vaderSentiment\n",
    "- sent_tokenize from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read CSV from Part I into DataFrame\n",
    "Next, let's load up the CSV that we got from Part I into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read the CSV from Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sentiment analysis with one text\n",
    "Before we analyze all seven texts, we should start with one text and identify the best strategy needed for our analysis.\n",
    "\n",
    "We'll start with the first text.\n",
    "\n",
    "### Step 3: Get the first text \n",
    "Declare a variable, and assign it the first text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Assign the first text to a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the text by sentence\n",
    "Declare another variable, where each item is a separate sentence. \n",
    "\n",
    "You can use nltk's sent_token, which can tokenize texts into sentences.\n",
    "\n",
    "You should expect 6,394 sentences in the resulting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split the text by sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate the sentiment score for the sentences\n",
    "Now that you have a list of sentences let's loop through them and get their respective sentiment.\n",
    "\n",
    "The code examples in the documentation are useful in getting yous started: https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "Create a new list containing the <strong>compound</strong> scores of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create a list of compound scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Click once to get pseudocode if you're stuck</strong></summary>\n",
    "    <ol>\n",
    "        <li>Declare a variable and assign an empty list to it</li>\n",
    "        <li>Declare a variable containing a SentimentIntensityAnalyzer object</li>\n",
    "        <li>Use a for loop to loop through the list from Step 4. In each loop:</li>\n",
    "        <ul>\n",
    "            <li>Use the SentimentIntensityAnalyzer object's .polarity_scores method to measure the current loop's sentence's score</li>\n",
    "            <li>Get the value of the \"compound\" key of the .polarity_scores method result</li>\n",
    "            <li>Append that value into the list declared above</li>\n",
    "        </ul>\n",
    "    </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create a DataFrame of sentiments for first text\n",
    "Now that you have:\n",
    "- a list of sentences\n",
    "- a list of compound scores of each sentence\n",
    "\n",
    "you can now create a DataFrame for them so that we can plot it later. \n",
    "\n",
    "![BookOneSentiment](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/BookOneSentiment.png)\n",
    "\n",
    "This is what you'll get once you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 6: Create a sentiment DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Plot the sentiment \n",
    "The moment of truth...let's plot the sentiment in the \"compound\" column, and let's see what we get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Plot compound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>What <em>did</em> we get? Click once to see our plot</strong></summary>\n",
    "    <img src=\"https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/BookOneSentenceSentimentPlot.png\">\n",
    "    <br>\n",
    "    <div>It's a really messy plot that oscillates wildly. Not really helpful :/</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Perform Savitsky-Golay filter on the sentiment data\n",
    "Savitsky-Golay filter removes noise from signals through polynomial smoothing. If we assume the signals to be continuous, and that the fluctuations are noise, we can use the filter to smoothen the signals. \n",
    "\n",
    "Reading: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.savgol_filter.html\n",
    "\n",
    "Here's what you need to do:\n",
    "1. Import savgol_filter from scipy.signal\n",
    "2. Transform 'compound' with the filter, with a window length of 151 and the 5th polynomial order\n",
    "3. Plot the transformed signal\n",
    "\n",
    "Feel free to change the window and polynomial order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import savgol filter\n",
    "\n",
    "# Plot the original 'compound' from the DataFrame\n",
    "\n",
    "# Declare a variable that contains the transformed signal through savgol filter\n",
    "\n",
    "# Plot the transformed signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Click once to see our plot</strong></summary>\n",
    "    <img src=\"https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/BookOneSentenceSentimentPlotWithSavGolFilter.png\n",
    "\">\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure sentiment by chapter\n",
    "It seems that splitting the text by sentence led to too many values. Instead, we can try to split the text by chapter.\n",
    "\n",
    "![ChapterSplitStrategy](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/ChapterSplitStrategy.png)\n",
    "\n",
    "In the following approach, these are the steps:\n",
    "1. <font color='red'>Split a full text into chapters</font>\n",
    "2. <font color='green'>Split each chapter into sentences</font>\n",
    "3. <font color='blue'>Measure the score for each sentence in a chapter</font>\n",
    "4. <font color='orange'>Get the average of the sentiment in each chapter based on the sentences</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Split the text by chapter\n",
    "Declare a variable, and split the text with \"CHAPTER\".\n",
    "\n",
    "Make sure your list has 17 items only, i.e. remove the first item in the list after splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Split the text by \"CHAPTER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Get a list of list of sentences\n",
    "Loop through the list of chapters, and in each chapter use sent_tokenize to break the chapter into a list of sentences.\n",
    "\n",
    "You will end up with a list containing 17 lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Get a list of list of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Click once to see the pseudocode</strong></summary>\n",
    "    <ol>\n",
    "        <li>Declare an empty list</li>\n",
    "        <li>Use a for loop to loop through the list of chapters. In each loop:</li>\n",
    "        <ul>\n",
    "            <li>Use sent_tokenize on the current chapter to split it into a list of sentences and assign it to a variable</li>\n",
    "            <li>Append the list of sentences to the empty list declared above</li>\n",
    "        </ul>\n",
    "    </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Measure the sentiment for each sentence in the list of list of sentences\n",
    "More loops ahead! \n",
    "\n",
    "In the list that you got from Step 9, loop through each sentence in each of your 17 lists and measure its sentiment.\n",
    "\n",
    "![ListOfListOfSentiments](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/ListOfListOfSentiments.png)\n",
    "\n",
    "What you have at the end is a list of lists that contain scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Click once to see the pseudocode</strong></summary>\n",
    "    <ol>\n",
    "        <li>Declare an empty list (List 1)</li>\n",
    "        <li>Declare a variable containing SentimentIntensityAnalyzer object</li>\n",
    "        <li>Use a for loop to loop through the list of list of sentences. In each loop:</li>\n",
    "        <ul>\n",
    "            <li>Declare a variable containing an empty list (List 2)</li>\n",
    "            <li>Use a for loop to loop through list of sentence. In each loop:</li>\n",
    "            <ul>\n",
    "                <li>Use the SentimentIntensityAnalyzer to get the polarity scores of the current sentence and assign the results to a variable</li>\n",
    "                <li>Get the value of the 'compound' key of the variable above</li>\n",
    "                <li>Append that 'compound' score to List 2</li>\n",
    "            </ul>\n",
    "            <li>Append the List 2 into List 1</li>\n",
    "        </ul>\n",
    "    </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 10: Measure the sentiment for each sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Average the list of list of scores\n",
    "Now that you have a list of list of scores, get the average for each list.\n",
    "\n",
    "![AveragedChapterSentiments](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/AveragedChapterSentiments.png)\n",
    "\n",
    "Since you have 17 chapters, you should end up wtih 17 scores in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Average the compound scores in each chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Create a DataFrame for the scores\n",
    "Now that you have a list of averaged sentiment scores, let's create a DataFrame containing two columns:\n",
    "- chapter\n",
    "- compound\n",
    "\n",
    "You'll see something like this.\n",
    "\n",
    "![BookOneDataFrameCompoundScores](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/BookOneDataFrameCompoundScores.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Plot the scores\n",
    "Now that you have the list of the averaged scores, let's plot it! \n",
    "\n",
    "Look out for how the sentiment changes throughout the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Plot the scores for Book 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Click once to see what we got</strong></summary>\n",
    "    <img src='https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/ChapterOneSentiments.png'>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis with all texts\n",
    "Now that we have tried the analysis on one text, let's plot the rest! \n",
    "\n",
    "### Step 14: Repeat Steps 8-12 with all texts\n",
    "You'll have to repeat the Steps 8-12 with each text in the list of texts.\n",
    "\n",
    "At the end, you'll be able to observe seven separate plots from the books.\n",
    "\n",
    "Make sure that you have the DataFrames for each text as well.\n",
    "\n",
    "P.S. Bear in mind that not all texts have the same string to denote chapter, i.e. \"CHAPTER\". Try looking into each text to see how you'd like to split them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 14a: Repeat Steps 8-12 with Book 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14b: Repeat Steps 8-12 with Book 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14c: Repeat Steps 8-12 with Book 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14d: Repeat Steps 8-12 with Book 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14e: Repeat Steps 8-12 with Book 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14f: Repeat Steps 8-12 with Book 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15: Normalize the chapter lengths\n",
    "You successfully made seven plots, but it is hard to compare between them because of their different lengths. \n",
    "\n",
    "If you tried, you'd be faced with a really messy plot.\n",
    "\n",
    "First things first - you'll need to normalize each DataFrame's chapter. \n",
    "\n",
    "![ChapterNormalization](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/ChapterNormalization.png)\n",
    "\n",
    "We'll need to normalize the chapter lengths by dividing each chapter's \"chapter\" with the max value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the \"chapter\" column for each DataFrame by the max number of chapters\n",
    "# Step 16a: Normalize the chapters in Book 1 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16b: Normalize the chapters in Book 2 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16c: Normalize the chapters in Book 3 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16d: Normalize the chapters in Book 4 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16e: Normalize the chapters in Book 5 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16f: Normalize the chapters in Book 6 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16g: Normalize the chapters in Book 7 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 17: Plot the compound scores from all the texts\n",
    "Now that you've normalized the chapters in all DataFrames, let's plot all scores on a single figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Plot compound scores from all texts in a single plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Click here once to see our plot</strong></summary>\n",
    "    <img src=\"https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectHarryPotter/CompoundScoreVsAllBookChaptersNormalized.png\">\n",
    "    <br>\n",
    "    <div>It seems like the sentiments oscillate throughout the book chapters, followed by a dip towards the end before going up again</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Part III\n",
    "What a Part!\n",
    "\n",
    "In this Part, you calculated and plotted sentiment scores throughout the full texts.\n",
    "\n",
    "We also had an optional part where you implemented a Savgol filter to filter the scores. \n",
    "\n",
    "In the next Part, you will analyze your text data in a different way, through word cloud visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
